{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "from keras import layers, models\n",
    "from keras import applications\n",
    "from keras import callbacks\n",
    "from pycocotools import mask as maskUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSegmentationModel:\n",
    "    def __init__(self, input_shape=(256, 256, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        base_model = applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "        base_model.trainable = True\n",
    "\n",
    "        for layer in base_model.layers[:20]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        conv1 = base_model.get_layer('block2a_expand_activation').output\n",
    "        conv2 = base_model.get_layer('block3a_expand_activation').output\n",
    "        conv3 = base_model.get_layer('block4a_expand_activation').output\n",
    "        conv4 = base_model.get_layer('block6a_expand_activation').output\n",
    "        conv5 = base_model.get_layer('top_activation').output\n",
    "\n",
    "        up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
    "        up6 = layers.concatenate([up6, conv4], axis=3)\n",
    "        conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "        conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "        up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "        up7 = layers.concatenate([up7, conv3], axis=3)\n",
    "        conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "        conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "        up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "        up8 = layers.concatenate([up8, conv2], axis=3)\n",
    "        conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "        conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "        up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "        up9 = layers.concatenate([up9, conv1], axis=3)\n",
    "        conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "        conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "        up10 = layers.Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(conv9)\n",
    "        conv10 = layers.Conv2D(32, 3, activation='relu', padding='same')(up10)\n",
    "        conv10 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv10)\n",
    "\n",
    "        outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv10)\n",
    "\n",
    "        model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def preprocess_data(self, annotation):\n",
    "        size = annotation['size']\n",
    "        mask_encoded = annotation['counts']\n",
    "        mask_encoded = np.array2string(annotation['counts'].numpy())\n",
    "        mask_encoded = mask_encoded[3:-2]\n",
    "        rle = {'size': size, 'counts': mask_encoded.replace('\\\\\\\\','\\\\')}\n",
    "        mask = maskUtils.decode(rle)\n",
    "        return mask\n",
    "    \n",
    "    def load_dataset(self, dataset_name='test_coco_dataset', split='train'):\n",
    "        return tfds.load(dataset_name, split=split)\n",
    "    \n",
    "    def prepare_data(self, dataset):\n",
    "        images = []\n",
    "        image_id_to_index = {}\n",
    "        image_id_to_mask = {}\n",
    "        masks = []\n",
    "\n",
    "        for idx, example in enumerate(dataset):\n",
    "            img_id = example['image_id'].numpy()\n",
    "            image = example['image'].numpy()\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            images.append(image)\n",
    "            image_id_to_index[img_id] = idx\n",
    "\n",
    "        images = np.array(images)\n",
    "        masks = np.zeros((len(images), 256, 256), dtype=np.uint8)\n",
    "\n",
    "        for example in dataset:\n",
    "            img_id = example['image_id'].numpy()\n",
    "            segmentation = example['segmentation']\n",
    "            mask = self.preprocess_data(segmentation)\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "            if img_id in image_id_to_mask:\n",
    "                existing_mask = image_id_to_mask[img_id]\n",
    "                combined_mask = np.maximum(existing_mask, mask)\n",
    "                image_id_to_mask[img_id] = combined_mask\n",
    "            else:\n",
    "                image_id_to_mask[img_id] = mask\n",
    "\n",
    "        masks = [image_id_to_mask[example['image_id'].numpy()] for example in dataset]\n",
    "\n",
    "        masks = np.array(masks).astype(np.float32)\n",
    "        images = images / 255.0\n",
    "        \n",
    "        return images, masks\n",
    "    \n",
    "    @staticmethod\n",
    "    def dice_loss(y_true, y_pred):\n",
    "        smooth = 1.\n",
    "        y_true_f = tf.keras.backend.flatten(y_true)\n",
    "        y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "        intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "        score = (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "        return 1. - score\n",
    "    \n",
    "    def data_generator(self, images, masks, batch_size):\n",
    "        while True:\n",
    "            for start in range(0, len(images), batch_size):\n",
    "                end = min(start + batch_size, len(images))\n",
    "                yield images[start:end], masks[start:end]\n",
    "\n",
    "    def train(self, train_images, train_masks, val_images, val_masks, epochs=3, batch_size=8):\n",
    "        model = self.model\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss=self.dice_loss, metrics=['accuracy'])\n",
    "        early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "        model_checkpoint = callbacks.ModelCheckpoint('unet_model2.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "        train_gen = self.data_generator(train_images, train_masks, batch_size)\n",
    "        val_gen = self.data_generator(val_images, val_masks, batch_size)\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=len(train_images) // batch_size,\n",
    "            validation_steps=len(val_images) // batch_size,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def plot_training(self, history):\n",
    "        acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        epochs_range = range(len(acc))\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, loss, label='Training Loss')\n",
    "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def display_prediction(self, image, mask, prediction, threshold=0.5):\n",
    "        prediction = (prediction > threshold).astype(np.uint8)\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Original Image')\n",
    "        plt.imshow(image)\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model = ImageSegmentationModel()\n",
    "dataset = segmentation_model.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_masks = segmentation_model.prepare_data(dataset)\n",
    "train_images, train_masks = train_images[:600], train_masks[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_masks = segmentation_model.prepare_data(dataset)\n",
    "val_images, val_masks = val_images[600:], val_masks[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = segmentation_model.train(train_images, train_masks, val_images, val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = segmentation_model.model.predict(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    segmentation_model.display_prediction(val_images[i], val_masks[i].squeeze(), val_predictions[i].squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
